# Machine Learning Basics @BflySoft

## Lecture 1: Introduction to Data Analytics
  * Data Analytics 개요 및 주요 개념
  * 데이터과학 프로젝트 절차
  * Machine Learning 방법론
  * Machine Learning 모델링 예시: PP 기사 분류 모형
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%201_Introduction%20to%20Data%20Analytics.pdf)], [[Video 1](https://www.youtube.com/watch?v=o9uEVxzFeR0&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=2)], [[Video_2](https://www.youtube.com/watch?v=IFe29PgOza4&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=3)], [[Video 3](https://www.youtube.com/watch?v=iqLEdf7SlVI&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=4)], [[Video_4](https://www.youtube.com/watch?v=94RHn0bRNV4&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=5)]

## Lecture 2: Multiple Linear Regression
  * MLR Formulation
  * MLR 학습: Ordinary Least Square
  * MLR 결과 해석
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%202_Multiple%20Linear%20Regression.pdf)], [[Video 1](https://www.youtube.com/watch?v=NknX91JdVA0&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=6)], [[Video 2](https://www.youtube.com/watch?v=s35EfV8lioM&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=7)]
  
## Lecture 3: Logistic Regression
  * Logistic Regression Formulation
  * Logistic Regression 학습: Gradient Descent
  * 다항 로지스틱 회귀분석
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%203_Logistic%20Regression.pdf)], [[Video 1](https://www.youtube.com/watch?v=PsVyx6erzrU&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=9)], [[Video 2](https://www.youtube.com/watch?v=vGMMulhLoYE&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=10)], [[Video 3](https://www.youtube.com/watch?v=3sZx4O2aQs8&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=11)], [[Video 4](https://www.youtube.com/watch?v=fhaXt0llHG4&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=12)]
  
## Lecture 4: Performance Evaluation
  * 회귀 모형의 성능 평가: MAE, MAPE, MSE, RMSE
  * 분류 모형의 성능 평가: 단순정확도, 균형정확도, F1-지표

## Lecture 5: Decision Tree
  * Classification Tree: 재귀적 분기, 가지치기
  * Regression Tree
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%205_Decision%20Tree.pdf)], [[Video](https://www.youtube.com/watch?v=w6eCV1GzsLs&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=18)]

## Lecture 6: Artificial Neural Network
  * 인공신경망 개요, Perceptron
  * Multi-layered Perceptron
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%206_Artificial%20Neural%20Network.pdf)], [[Video 1](https://www.youtube.com/watch?v=s0ObHKy_MYk&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=21)], [[Video 2](https://www.youtube.com/watch?v=YitouyZ-S94&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=22)]
  
## Lecture 7: Deep Neural Network & Convolutional Neural Network
  * 심층신경망 개요
  * 합성곱 신경망: Convolution 개념, 대표적 CNN 구조
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%207_Deep%20Neural%20Network_CNN.pdf)]

## Lecture 8: Recurrent Neural Network & Auto Encoder
  * 순환신경망, LSTM, GRU
  * 오토인코더
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%208_RNN_Auto%20Encoder.pdf)]
  
## Lecture 9: Ensemble Learning
  * 앙상블 배경
  * 배깅 & 랜덤 포레스트
  * AdaBoost & Gradient Boosting Machine
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%209_Ensemble%20Learning.pdf)], [[Video 1](https://www.youtube.com/watch?v=Y8xfvgKc_KM&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=24)], [[Video 2](https://www.youtube.com/watch?v=giIaZDXu2No&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=25)], [[Video 3](https://www.youtube.com/watch?v=wB0ELX15kN8&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=26)], [[Video 4](https://www.youtube.com/watch?v=Y2rsmO6Nr4I&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=27)], [[Video 5](https://www.youtube.com/watch?v=1qnZ6JKZTNI&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=28)]
  
## Lecture 10: Anomaly Detection
  * 이상치 탐지
  * 밀도 기반 이상치 탐지
  * 모델 기반 이상치 탐지
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%2010_Anomaly%20Detection.pdf)]

## Lecture 11: Clustering
  * 군집화 개요 및 타당성 평가 지표
  * K-평균 군집화
  * 계층적 군집화
  * 밀도 기반 군집화: DBSCAN
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%2011_Clustering.pdf)], [[Video 1](https://www.youtube.com/watch?v=k885zMo0jQs&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=33)], [[Video 2](https://www.youtube.com/watch?v=QJB6eClNQVI&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=34)], [[Video 3](https://www.youtube.com/watch?v=sMMbAgKVwAk&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=35)], [[Video 4](https://www.youtube.com/watch?v=O_EigN9iF6E&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=36)]

## Lecture 12: Recommendation Systems
  * 추천시스템 개요
  * 아이템 기반 추천 [[Video](https://www.youtube.com/watch?v=Y1ZphMeDjPA&list=PLetSlH8YjIfWKLpMp-r6enJvnk6L93wz2&index=31)]
  * 협업 필터링 기반 추천
  * 행렬 분해 기반 추천 
  * [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Lecture%2012_Recommendation%20Systems.pdf)]

# Text Analytics @BflySoft

## Introduction to Text Analytics

## Topic 1: Introduction to Text Analytics [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Introduction%20to%20Text%20Analytics.pdf)]
* Text Analytics: Backgrounds, Applications, & Challanges, and Process [[Video](https://www.youtube.com/watch?v=UInnl60pzkA&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=2)]
* Text Analytics Process [[Video](https://www.youtube.com/watch?v=Y0zrFVZqnl4&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=3)]

## Topic 2: Text Preprocessing [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Text%20Preprocessing.pdf)]
* Introduction to Natural Language Processing (NLP) [[Video](https://www.youtube.com/watch?v=NLaxlUKFVw4&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=5&t=0s)]
* Lexical analysis [[Video](https://www.youtube.com/watch?v=5gt1KvkkOlc&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=5)]
* Syntax analysis & Other topics in NLP [[Video](https://www.youtube.com/watch?v=DdFKFqZyv5s&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=6)]
* Reading materials
  * Cambria, E., & White, B. (2014). Jumping NLP curves: A review of natural language processing research. IEEE Computational intelligence magazine, 9(2), 48-57. ([PDF](http://ieeexplore.ieee.org/abstract/document/6786458/))
  * Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12(Aug), 2493-2537. ([PDF](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf))
  * Young, T., Hazarika, D., Poria, S., & Cambria, E. (2017). Recent trends in deep learning based natural language processing. arXiv preprint arXiv:1708.02709. ([PDF](https://arxiv.org/pdf/1708.02709.pdf))
  * NLP Year in Review - 2019 ([Medium Post](https://medium.com/dair-ai/nlp-year-in-review-2019-fb8d523bcb19))

## Topic 3: Text Representation I: Classic Methods [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Text%20Representation%20I_Classic%20Methods.pdf)]
* Bag of words, Word weighting, N-grams [[Video](https://www.youtube.com/watch?v=DMNUVGbLp-0&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=7)]

## Topic 5: Text Representation II: Distributed Representation [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Text%20Representation%20II%20-%20Distributed%20Representation.pdf)]
* Neural Network Language Model (NNLM) [[Video](https://www.youtube.com/watch?v=bvSHJG-Fz3Y&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=8)]
* Word2Vec [[Video](https://www.youtube.com/watch?v=s2KePv-OxZM&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=10&t=0s)]
* GloVe [[Video](https://www.youtube.com/watch?v=JZI74rrMb_M&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=10)]
* FastText, Doc2Vec, and Other Embeddings [[Video](https://www.youtube.com/watch?v=oRz6llDhFW8&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=11)]
* Reading materials
  * Bengio, Y., Ducharme, R., Vincent, P., & Jauvin, C. (2003). A neural probabilistic language model. Journal of machine learning research, 3(Feb), 1137-1155. ([PDF](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf))
  * Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781. ([PDF](https://arxiv.org/pdf/1301.3781.pdf))
  * Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111-3119). ([PDF](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf))
  * Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543). ([PDF](http://www.aclweb.org/anthology/D14-1162))
  * Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2016). Enriching word vectors with subword information. arXiv preprint arXiv:1607.04606. ([PDF](https://arxiv.org/pdf/1607.04606.pdf))

## Topic 6: Dimensionality Reduction [[Slide](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Dimensionality%20Reduction.pdf)]
* Dimensionality Reduction Overview, Supervised Feature Selection [[Video](https://www.youtube.com/watch?v=Gldr3LQvnSA&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=12)]
* Unsupervised Feature Extraction [[Video](https://www.youtube.com/watch?v=XYCVzp0NGFc&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=13)]
* Reading materials
  * Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990). Indexing by latent semantic analysis. Journal of the American society for information science, 41(6), 391-407. ([PDF](https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291097-4571%28199009%2941%3A6%3C391%3A%3AAID-ASI1%3E3.0.CO%3B2-9))
  * Landauer, T. K., Foltz, P. W., & Laham, D. (1998). An introduction to latent semantic analysis. Discourse processes, 25(2-3), 259-284. ([PDF](https://www.tandfonline.com/doi/pdf/10.1080/01638539809545028?needAccess=true))
  * Maaten, L. V. D., & Hinton, G. (2008). Visualizing data using t-SNE. Journal of machine learning research, 9(Nov), 2579-2605. ([PDF](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)) ([Homepage](https://lvdmaaten.github.io/tsne/))

## Topic 7: Language Modeling & Pre-trained Models [[Slide 1](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Seq2Seq%20Learning_Transformer.pdf)], [[Slide 2](https://github.com/pilsung-kang/Machine-Learning-Basics-Bflysoft/blob/master/Pretrained%20Models_ELMo_GPT_BERT_GPT2_upload.pdf)]
* Sequence-to-Sequence Learning [[Video](https://www.youtube.com/watch?v=0lgWzluKq1k&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=17)]
* Transformer [[Video](https://www.youtube.com/watch?v=Yk1tV_cXMMU&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=18)]
* ELMo: Embeddings from Language Models [[Video](https://www.youtube.com/watch?v=zV8kIUwH32M&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=19)]
* GPT: Generative Pre-Training of a Language Model [[Video](https://www.youtube.com/watch?v=o_Wl29aW5XM&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=20)]
* BERT: Bidirectional Encoder Representations from Transformer [[Video](https://www.youtube.com/watch?v=IwtexRHoWG0&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=21)]
* GPT-2: Language Models are Unsupervised Multitask Learners [[Video](https://www.youtube.com/watch?v=8hd2Q-3-BsQ&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=22)]
* Transformer to T5 [[Slide](https://drive.google.com/file/d/181l1g9kSI8ELVy7mVtlil-bOrFLaiWcz/view)], [[Video](https://www.youtube.com/watch?v=v7diENO2mEA&feature=youtu.be)], Presented by Yukyoung Lee.
* Reading Materials
  * Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems (pp. 3104-3112). ([PDF](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf))
  * Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473. ([PDF](https://arxiv.org/pdf/1409.0473.pdf))
  * Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008). ([PDF](http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf))
  * Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. arXiv preprint arXiv:1802.05365. ([PDF](https://arxiv.org/pdf/1802.05365.pdf))
  * Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training. ([PDF](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf))
  * Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. ([PDF](https://arxiv.org/pdf/1810.04805.pdf))
  * Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsupervised multitask learners. OpenAI Blog, 1(8), 9. ([PDF](https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/PAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask-%20Learners.pdf))

## Topic 8: Topic Modeling as a Distributed Reprentation
* Topic modeling overview & Latent Semantic Analysis (LSA), Probabilistic Latent Semantic Analysis: pLSA [[Video](https://www.youtube.com/watch?v=J1ri0EQnUOg&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=14)]
* LDA: Document Generation Process [[Video](https://www.youtube.com/watch?v=WR2On5QAqJQ&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=15)]
* LDA Inference: Collapsed Gibbs Sampling, LDA Evaluation [[Video](https://www.youtube.com/watch?v=iwMSCsiL6wQ&list=PLetSlH8YjIfVzHuSXtG4jAC2zbEAErXWm&index=16)]
* Reading Materials
  * Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990). Indexing by latent semantic analysis. Journal of the American society for information science, 41(6), 391. ([PDF](http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf))
  * Dumais, S. T. (2004). Latent semantic analysis. Annual review of information science and technology, 38(1), 188-230.
  * Hofmann, T. (1999, July). Probabilistic latent semantic analysis. In Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence (pp. 289-296). Morgan Kaufmann Publishers Inc. ([PDF](http://www.iro.umontreal.ca/~nie/IFT6255/Hofmann-UAI99.pdf))
  * Hofmann, T. (2017, August). Probabilistic latent semantic indexing. In ACM SIGIR Forum (Vol. 51, No. 2, pp. 211-218). ACM.
  * Blei, D. M. (2012). Probabilistic topic models. Communications of the ACM, 55(4), 77-84. ([PDF](http://delivery.acm.org/10.1145/2140000/2133826/p77-blei.pdf?ip=175.114.11.68&id=2133826&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1524148444_1a7687d674528eeabc9a97afa2db5a29))
  * Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of machine Learning research, 3(Jan), 993-1022. ([PDF](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf))
* Recommended video lectures
  * LDA by D. Blei ([Lecture Video](http://videolectures.net/mlss09uk_blei_tm/))
  * Variational Inference for LDA by D. Blei ([Lecture Video](https://www.youtube.com/watch?v=Dv86zdWjJKQ&t=113s))
  
